---
title: "EPIC run Cultivars - parallelized"
author: "Katerina Krizova"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output: 
  pdf_document: 
    toc: yes
    toc_depth: 3
---

\newpage 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message=FALSE, fig.dim = c(8, 4))

# install.packages("tidyverse", dependencies = T)
# install.packages("gdata")
require(tidyverse)
require(gdata) # write.fwf
library(sf)
library(sp)
library(rgdal)

```

\newpage

# INITIAL SETUP

## paths 

```{r echo = T}
path_in <- "c:/Users/krizovak/Documents/__EPIC__/R/" 

path_met <- "C:/Users/krizovak/Documents/__EPIC__/R/_tables/v3_czsk/" 
path_tab <- "c:/Users/krizovak/Documents/__EPIC__/R/_tables/" 
path_shp <- "c:/Users/krizovak/Documents/__EPIC__/R/_shapefiles/" 
path_epic <- "c:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/" 

path_out <- "c:/Users/krizovak/Documents/__EPIC__/R/_cultivarRESULTS/" 
```

## time period

```{r echo = T}

period <- 1989:1999
```

## crop params

```{r CROP PARAMS}

# crop <- "ALFA"
# crop <- "BARL"
# crop <- "CSIL"
crop <- "CORN"
# crop <- "OATS"
# crop <- "FPEA"
# crop <- "POTA"
# crop <- "RAPE"
# crop <- "RYE"
# crop <- "SGBT"
# crop <- "SUNF"
# crop <- "SOYB"
# crop <- "WWHT"

# crop ID + seasonality

if(crop == "ALFA"){
  cropid <- 31 
  seas <- "OTH"
} else if (crop == "BARL"){
  cropid <- 14
  seas <- "SPG"
} else if (crop == "CSIL"){
  cropid <- 29
  seas <- "SPG"
} else if (crop == "CORN"){
  # cropid <- 2 # old cult; 155 = COR3
  cropid <- 155
  seas <- "SPG"
} else if (crop == "OATS"){
  cropid <- 16
  seas <- "SPG"
} else if (crop == "FPEA"){
  cropid <- 26
  seas <- "SPG"
} else if (crop == "POTA"){
  cropid <- 51
  seas <- "SPG"
} else if (crop == "RAPE"){
  cropid <- 122
  seas <- "WIN"
} else if (crop == "RYE") {
  cropid <- 19
  seas <- "WIN"
} else if (crop == "SGBT"){
  cropid <- 62
  seas <- "SPG"
} else if (crop == "SUNF"){
  cropid <- 7
  seas <- "SPG"
} else if (crop == "SOYB"){
  cropid <- 1
  seas <- "SPG"
} else if (crop == "WWHT"){
  cropid <- 10
  seas <- "WIN"
} else {
  print("ZEROO")
}

# basal and optimal temperature 

if(crop == "ALFA"){
  top <- 25 
  tbs <- 1 
} else if (crop %in% c("BARL", "OATS", "WWHT")){
  top <- 15 
  tbs <- 0 
} else if (crop == "CSIL"){
  top <- 25 
  tbs <- 10 
} else if (crop == "CORN"){ # COR3 top and tbs parameters
  top <- 22.5 
  tbs <- 6.5
} else if (crop == "FPEA"){
  top <- 15 
  tbs <- 1
} else if (crop == "POTA"){
  top <- 17 
  tbs <- 7
} else if (crop == "RAPE"){
  top <- 13.5 
  tbs <- 0
} else if (crop == "RYE"){
  top <- 12.5 
  tbs <- 0
} else if (crop == "SGBT"){
  top <- 22
  tbs <- 4
} else if (crop %in% c("SOYB", "SUNF")){
  top <- 25
  tbs <- 10
} else {
  print("ZEROO")
}

```
* crop: `r crop`

* crop ID: `r cropid`

* seasonality: `r seas`

* basal temperature: `r tbs`

* optimal temperature: `r top`

## geospatial backgroud

10 km grids

* 877 for CZ
* 550 for SK

```{r}
czsk_shp <- st_read(paste0(path_shp, "CS_CGMS10k_SpatRef_v0.shp"), quiet = T) # CZ i SK crs = 5514, 
plot(czsk_shp)

czsk_tab <- read.table(paste0(path_tab, "CS_GRID_OKRES_VO_parallelFolder.csv"), header = TRUE, sep = ";")
czsk_tab$CGMS_ID <- as.character(czsk_tab$CGMS_ID)
czsk_tab$CGMS_ID <- as.factor(czsk_tab$CGMS_ID)
print(czsk_tab[duplicated(czsk_tab$CGMS_ID),])

```


# CALCULATING PHU FROM DLY FILES

calculates optimal PHU (potential heat units) for each cultivar

required parameters: **tbs** and **top**

```{r PHU FRACTION FROM DLY NEW}

crop_cal <- read.table(paste0(path_out, crop, "/", crop, "_cultivars.csv"), header = TRUE, sep = ",") # == cultivars

czsk_grid <- czsk_tab %>% 
  mutate(dly = paste0(CGMS_ID, ".dly")) # selected grids for CZSK without overlaps, n=1427
Ldly <- czsk_grid$dly

a_cols <- c("year", "month", "day", "srad", "tmax", "tmin", "prcp", "rhum", "wind")
# phuFR <- data.frame()
file.create(paste0(path_out, crop, "/", crop, "_phuFR.csv"))
phufile <- paste0(path_out, crop, "/", crop, "_phuFR.csv")

for(i in Ldly) {  # TAKES AGES !!!
  a <- read.table(paste0(path_met, i)) # reads the DLY file
  names(a) <- a_cols  # rename the columns
  # a$month <- sprintf("%02d", as.numeric(a$month)) # month in format 01
  # a$day <- sprintf("%02d", as.numeric(a$day)) # day in format 01
  # a$datefull <- paste(a$year, a$month, a$day, sep = "-")
  # a$datefull <- as.Date(a$datefull, format=c("%Y-%m-%d")) # creates full date
  ab <- a %>% 
    select(year, tmax, tmin) %>% 
    filter(year %in% period) %>%
    mutate(tavg = (tmax+tmin)/2) %>% # average temperature required for PHU calculation
    group_by(year) %>%
    mutate(julday = seq_along(tmax)) %>%
    mutate(phu_fr = case_when(tavg <= tbs ~ 0,
                           (tavg > tbs)&(tavg < top) ~ (tavg-tbs),
                           tavg >= top ~ (top-tbs))) 
  ab$GRID <- paste0(i) # adds column with the DLY name
  ab$GRID <- as.numeric(str_sub(ab$GRID,1,nchar(ab$GRID)-4))
  ab$CROP <- crop
  ac <- merge(ab, czsk_tab[ , c("CGMS_ID", "VO_TYP")], by.x = "GRID", by.y = "CGMS_ID")
  write.table(ac, file = paste(phufile), sep = ";",
              append=T, quote = F, col.names = F, row.names = F) 
}

rm(a)
rm(ab)
rm(ac)

```

```{r AVG PHU FOR PROD ZONES}

# *** READ *** READ *** READ ** READ ***
phuFR <- read.table(paste0(path_out, crop, "/", crop, "_phuFR.csv"), header = F, sep = ";")
crop_cal <- read.table(paste0(path_out, crop, "/", crop, "_cultivars.csv"), header = TRUE, sep = ",") # == cultivars
# *** READ *** READ *** READ ** READ ** year, tmax, tmin, datefull

crop_cal <- crop_cal %>% 
  mutate(VO_TYP = case_when(CULT %in% c("k1", "k2", "k3") ~ 1,
                            CULT %in% c("r1", "r2", "r3") ~ 2,
                            CULT %in% c("b1", "b2", "b3") ~ 3,
                            CULT %in% c("h1", "h2", "h3") ~ 4))

phuFR_colnam <- c("GRID","year","tmax","tmin","tavg",
                  "julday", "phu_fr","crop", "VO_TYP")
names(phuFR) <- phuFR_colnam
phuFR$GRID <- factor(phuFR$GRID)
phuFR$VO_TYP <- factor(phuFR$VO_TYP)
Lvo <-levels(phuFR$VO_TYP)

PHU <- data.frame()

if(seas == "SPG"){
  for(i in Lvo){
    phu_vo <- phuFR %>% 
      filter(VO_TYP == i) %>% 
      distinct()
    crop_vo <- crop_cal %>% 
      filter(VO_TYP == i) %>% 
      select(CULT, PLN_JUL, HRV_JUL, LVP, PLN_MON, PLN_DAY, HRV_MON, HRV_DAY)
    a <- merge(phu_vo, crop_vo)
    Lcult <- crop_vo$CULT
    for(j in Lcult){
      b <- a %>% 
        filter(CULT == j) %>% # round for specific cultivar
        filter(julday >= PLN_JUL & julday <= HRV_JUL) %>% # filter only data for growing period
        group_by(GRID, year) %>% 
        summarise(CULT, PLN_JUL, HRV_JUL, LVP, PLN_MON, PLN_DAY, HRV_MON, HRV_DAY, 
                  crop, julday, PLN_JUL, HRV_JUL, VO_TYP, phusum = sum(phu_fr)) %>% # sum of PHU fraction
        filter(julday == HRV_JUL) %>% # sum of PHU fraction for each year
        group_by(GRID) %>% 
        summarise(CULT, PLN_JUL, HRV_JUL, LVP, PLN_MON, PLN_DAY, HRV_MON, HRV_DAY, 
                  crop, julday, PLN_JUL, HRV_JUL, VO_TYP, avg_phusum = mean(phusum)) %>% # avg PHU for every grid
        distinct()
      df <- data.frame(b) 
      PHU <- rbind(PHU, df)
    }
  }
} else if (seas == "WIN"){
    for(i in Lvo){
    phu_vo <- phuFR %>% 
      filter(VO_TYP == i) %>% 
      distinct()
    crop_vo <- crop_cal %>% 
      filter(VO_TYP == i) %>% 
      select(CULT, PLN_JUL, HRV_JUL, LVP, PLN_MON, PLN_DAY, HRV_MON, HRV_DAY)
    c <- merge(phu_vo, crop_vo)
    Lcult <- crop_vo$CULT
    for(j in Lcult){
      d <- c %>% 
        filter(CULT == j) %>% 
        group_by(GRID, year) %>% 
        subset(!(year == 1989 & julday < PLN_JUL)) %>% 
        ungroup() %>% 
        filter(julday <= HRV_JUL) %>% # filter only data for growing period
        group_by(GRID, year) %>% 
        summarise(CULT, PLN_JUL, HRV_JUL, LVP, PLN_MON, PLN_DAY, HRV_MON, HRV_DAY, 
                  crop, julday, PLN_JUL, HRV_JUL, VO_TYP, phusum = sum(phu_fr)) %>% # sum of PHU fraction
        filter(julday == HRV_JUL) %>% # sum of PHU fraction for each year
        group_by(GRID) %>% 
        summarise(CULT, PLN_JUL, HRV_JUL, LVP, PLN_MON, PLN_DAY, HRV_MON, HRV_DAY, 
                  crop, julday, PLN_JUL, HRV_JUL, VO_TYP, avg_phusum = mean(phusum)) %>% # avg PHU for every grid
        distinct()
      df <- data.frame(d) 
      PHU <- rbind(PHU, df)
    }
  }
}
  
phu_cal <- PHU %>% 
  group_by(GRID) %>% 
  mutate(iphusum = mean(avg_phusum)) %>% 
  mutate(phusum = iphusum*0.8) %>% # 90% of ideal PHU # 80% of ideal PHU
  ungroup()

# *** WR *** WR *** WR ** WR ***
write.table(phu_cal, paste0(path_out, crop, "/", crop, "_phu_sum.csv"),
            row.names = F, quote = F, sep = ";")
# *** WR *** WR *** WR ** WR ***

```

# PHU CALENDAR AND MAPS

*`r crop`_phu_cal*

```{r PHU CALENDAR}

# *** READ *** READ *** READ ** READ ***
phu_sum <- read.table(paste0(path_out, crop, "/", crop, "_phu_sum.csv"), header = T, sep = ";")
# *** READ *** READ *** READ ** READ **

phu_cal <- phu_sum %>% 
  mutate(cropid = cropid) %>% 
  rename("PHU" = phusum) %>% 
  rename("scenario" = CULT) %>% 
  select(scenario, GRID, cropid, crop, PLN_JUL, HRV_JUL, LVP, PHU) %>% 
  arrange(GRID, scenario) %>% 
  distinct() %>%
  # dplyr::mutate(runid = row_number()) %>% 
  mutate(ctry = case_when(GRID %in% 1:891 ~ "CZ",
                           GRID %in% 1000:6000 ~ "SK"))

# 
# # merge VO_TYP -> select VO_TYP-specific scenario
# 
# phu_cal_VO <- merge(phu_cal, czsk_tab[, c("CGMS_ID", "parallel", "VO_TYP")], 
#                                 by.x = "GRID", by.y = "CGMS_ID") 


# *** WR *** WR *** WR ** WR ***
# write.table(phu_cal, paste0(path_out, crop, "/", crop, "_phu_cal.csv"), 
#             row.names = F, quote = F, sep = ";")
# *** WR *** WR *** WR ** WR ***

phu4map <- phu_cal %>% 
  filter(str_detect(scenario, "1"))

phumap <- merge(czsk_shp, phu4map, by.x = "CGMS_ID", by.y = "GRID", all.x = T)
phumap$PHU <- round(phumap$PHU, 0)

# PHU MAP

ggplot(phumap, aes(geometry = geometry, fill= PHU))+ 
  geom_sf()+
  # geom_sf_label(aes(label = PHU))+
  geom_sf_text(aes(label = PHU), colour = "white", size = 1.5, fontface = "bold")+
  ggtitle(paste0("Average PHU for ", crop, " in 1989-2019")) + 
  scale_fill_gradient("", 
    low = "yellow",
    # mid = "green",
    high = "darkmagenta",
    space = "Lab",
    na.value = "grey50",
    guide = "colourbar",
    aesthetics = "fill")+
  coord_sf()+
  theme_void()+
  theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), 
        axis.ticks.y = element_blank(), axis.text.y = element_blank(),
        plot.title = element_text(hjust = 0.5))
 
ggsave(paste0(path_out, crop, "/", crop, "_map_avgPHU.jpg"), width = 30, height = 20, units = "cm")

# PLN_JUL MAP

scen_maps <- phu_cal %>% 
  mutate(sc = case_when(str_detect(scenario, "1") ~ 1,
                        str_detect(scenario, "2") ~ 2,
                        str_detect(scenario, "3") ~ 3)) %>% 
  merge(czsk_shp, by.x = "GRID", by.y = "CGMS_ID", all.y = T) 

for(i in 1:3){
  a <- scen_maps %>% filter(sc == i)
  gp <- ggplot(a, aes(geometry = geometry, fill= PLN_JUL))+ 
    geom_sf()+
    # geom_sf_label(aes(label = PHU))+
    geom_sf_text(aes(label = PLN_JUL), colour = "white", size = 1.5, fontface = "bold")+
    ggtitle(paste0("Harvesting day (julian) for ", crop, " / scenario:", i)) + 
    scale_fill_gradient("", 
                        low = "forestgreen",
                        # mid = "green",
                        high = "red",
                        space = "Lab",
                        na.value = "grey50",
                        guide = "colourbar",
                        aesthetics = "fill")+
    coord_sf()+
    theme_void()+
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), 
          axis.ticks.y = element_blank(), axis.text.y = element_blank(),
          plot.title = element_text(hjust = 0.5))
  print(gp)
}

# HRV_JUL MAP

for(i in 1:3){
  a <- scen_maps %>% filter(sc == i)
  gh <- ggplot(a, aes(geometry = geometry, fill= HRV_JUL))+ 
    geom_sf()+
    # geom_sf_label(aes(label = PHU))+
    geom_sf_text(aes(label = PLN_JUL), colour = "white", size = 1.5, fontface = "bold")+
    ggtitle(paste0("Planting day (julian) for ", crop, " / scenario:", i)) + 
    scale_fill_gradient("", 
                        low = "gold",
                        # mid = "green",
                        high = "red",
                        space = "Lab",
                        na.value = "grey50",
                        guide = "colourbar",
                        aesthetics = "fill")+
    coord_sf()+
    theme_void()+
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), 
          axis.ticks.y = element_blank(), axis.text.y = element_blank(),
          plot.title = element_text(hjust = 0.5))
  print(gh)
}


# LVP MAP

for(i in 1:3){
  a <- scen_maps %>% filter(sc == i)
  gl <- ggplot(a, aes(geometry = geometry, fill = LVP))+ 
    geom_sf()+
    # geom_sf_label(aes(label = PHU))+
    geom_sf_text(aes(label = PLN_JUL), colour = "white", size = 1.5, fontface = "bold")+
    ggtitle(paste0("Length of vegetation period for ", crop, " / scenario:", i)) + 
    scale_fill_gradient("days", 
                        low = "cyan4",
                        # mid = "green",
                        high = "darkblue",
                        space = "Lab",
                        na.value = "grey50",
                        guide = "colourbar",
                        aesthetics = "fill")+
    coord_sf()+
    theme_void()+
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), 
          axis.ticks.y = element_blank(), axis.text.y = element_blank(),
          plot.title = element_text(hjust = 0.5))
  print(gl)
}

```

# PARALLELIZATION OF EPIC SIMULATIONS

split runs in 8 different folders to ensure faster simulations

1 year simulated in 4-6 s

**CZ**

  1) 1-175
  2) 176-350
  3) 351-525
  4) 526-701
  5) 702-890
  
**SK**

  6) 1336-2641
  7) 2642-3734
  8) 3735-5425

```{r PARALLELIZATION}

phu_cal_PAR <- merge(phu_cal, czsk_tab[, c("CGMS_ID", "parallel", "VO_TYP")], 
                                by.x = "GRID", by.y = "CGMS_ID") %>% 
   filter((scenario %in% c("k1", "k2", "k3") & VO_TYP == 1) |
         (scenario %in% c("r1", "r2", "r3") & VO_TYP == 2) |
         (scenario %in% c("b1", "b2", "b3") & VO_TYP == 3) |
         (scenario %in% c("h1", "h2", "h3") & VO_TYP == 4)) %>%  
          dplyr::mutate(runid = row_number()) # merge grid props and filter scenarios for specific VO_TYP

# *** WR *** WR *** WR ** WR ***
write.table(phu_cal_PAR, paste0(path_out, crop, "/", crop, "_phu_cal_PAR.csv"),
            row.names = F, quote = F, sep = ";")
# *** WR *** WR *** WR ** WR ***
```

## DIRECTORIES

create directories for storing EPIC input files:

```{r PARALLEL DIRS, echo=T, message=F}

# cult

unlink(paste0(path_out, crop, "/epicrun"), recursive=TRUE)
unlink(paste0(path_out, crop, "/epicrun_parallel"), recursive=TRUE)
unlink(paste0(path_out, crop, "/OPSC"), recursive=TRUE)
unlink(paste0(path_out, crop, "/OPSC_parallel"), recursive=TRUE)
unlink(paste0(path_out, crop, "/SITE_parallel"), recursive=TRUE)
unlink(paste0(path_out, crop, "/SOIL_parallel"), recursive=TRUE)
unlink(paste0(path_out, crop, "/PARM"), recursive=TRUE) # delete folders form prec. run

# dir.create (paste0(path_out, crop, "/epicrun"), showWarnings = FALSE)
dir.create(paste0(path_out, crop, "/epicrun_parallel"), showWarnings = FALSE)
# dir.create (paste0(path_out, crop, "/OPSC"), showWarnings = FALSE)
dir.create (paste0(path_out, crop, "/OPSC_parallel"), showWarnings = FALSE)
dir.create (paste0(path_out, crop, "/SITE_parallel"), showWarnings = FALSE)
dir.create (paste0(path_out, crop, "/SOIL_parallel"), showWarnings = FALSE)
# dir.create (paste0(path_out, crop, "/PARM"), showWarnings = FALSE)
dir.create (paste0(path_out, crop, "/_outs"), showWarnings = FALSE) # create new ones

Louts <- list.files(paste0(path_out, crop, "/_outs/"), pattern = ".ACM|.ACY")
file.remove(paste0(path_out, crop, "/_outs/", Louts)) # ACM and ACY files removal from _outs folder

# v4

for(i in 1:8) {
  path_temp <- paste0("c:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/EPIC_CS_", i, "/")
  unlink(paste0(path_temp, "EPIC0810"), recursive=TRUE)
  unlink(paste0(path_temp, "OPSC"), recursive=TRUE)
  unlink(paste0(path_temp, "SITE"), recursive=TRUE)
  unlink(paste0(path_temp, "SOIL"), recursive=TRUE)
  dir.create(paste0(path_temp, "EPIC0810"))
  dir.create(paste0(path_temp, "OPSC"))
  dir.create(paste0(path_temp, "SITE"))
  dir.create(paste0(path_temp, "SOIL"))
  # copy EPIC0810 files
  oldDir <- paste0("c:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/_EPIC_CS_0_/EPIC0810/")
  newDir<- paste0(path_temp, "EPIC0810/")
  L <- list.files(paste0(oldDir))
  file.copy(from = paste0(oldDir, L), 
          to = paste0(newDir, L), overwrite = TRUE)
  # copy SITE files
  oldDir <- paste0("c:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/_EPIC_CS_0_/SITE/")
  newDir<- paste0(path_temp, "SITE/")
  L <- list.files(paste0(oldDir))
  file.copy(from = paste0(oldDir, L), 
          to = paste0(newDir, L), overwrite = TRUE)
  # copy SOIL files
  oldDir <- paste0("c:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/_EPIC_CS_0_/SOIL/")
  newDir<- paste0(path_temp, "SOIL/")
  L <- list.files(paste0(oldDir))
  file.copy(from = paste0(oldDir, L), 
          to = paste0(newDir, L), overwrite = TRUE)
}

```

\newpage

# EPIC INPUT FILES


## EPICRUN

*EPIC/EPIC0810/epicrun_x*

EPICRUN for initial calibrations runs works with only 1 SIT and 1 SOL file for all grids

*SIT*

    + CZ: 119
    + SK: 6135

*SOL* 

    + CZ: 10
    + SK: 7
    
*OPC* created for each 'runid' (runid 167 = 167.opc)

*DLY* created for each 'runid' (runid 167 = 167.dly) / same for WP1

*WINDID* set as 1 for each 'runid'


```{r PARALLEL epicrun}

# *** READ *** READ *** READ ** READ ***
phu_cal_PAR <- read.table(paste0(path_out, crop, "/", crop, "_phu_cal_PAR.csv"), header = TRUE, sep = ";")
# *** READ *** READ *** READ ** READ ***

epicrun1 <- phu_cal_PAR %>%
  select(parallel, runid, GRID) %>%
  mutate(SIT = case_when(phu_cal_PAR$ctry == "CZ" ~ 119,
                         phu_cal_PAR$ctry == "SK" ~ 6135)) %>%
  mutate(SOL = case_when(phu_cal_PAR$ctry == "CZ" ~ 10,
                         phu_cal_PAR$ctry == "SK" ~ 7)) %>%
  mutate(OPC = runid) %>%
  mutate(WP1 = GRID) %>%
  mutate(WP1 = GRID) %>%
  mutate(WS2 = 0) %>%
  mutate(DLY = GRID) %>%
  mutate(WINDID = 1) 

print(phu_cal_PAR[duplicated(phu_cal_PAR$runid),])
print(czsk_tab[duplicated(czsk_tab$CGMS_ID),])


# print files to cult folder

for(i in 1:8) {
  parall <- epicrun1 %>% 
    filter(parallel == i)
  dir.create(paste0(path_out, crop, "/epicrun_parallel/epicrun_", i), showWarnings = FALSE)
  path_temp <- paste0(path_out, crop, "/epicrun_parallel/epicrun_", i)
    for(j in parall$runid){
      epicrun <- parall %>% 
        filter(runid == j) %>% 
        select(runid, SIT, WP1, WS2, WINDID, SOL, OPC, DLY)
      write.fwf(epicrun, paste0(path_temp, "/epicrun_", j, ".dat"),
          rownames = FALSE, colnames = FALSE, append=FALSE,
          width = c(8,8,8,8,8,8,8,8), sep = "")
    }
}

# copy files to v4

for(i in 1:8) {
  path_temp <- paste0(path_out, crop, "/epicrun_parallel/epicrun_", i, "/") # set path to the folder
  Lepr <- list.files(path_temp, pattern = "epicrun") # get list of opc files in folder
  newDir <- (paste0(path_epic, "EPIC_CS_", i, "/EPIC0810/")) # set new folder (EPIC v4)
  file.copy(from = paste0(path_temp, Lepr),   # copy opc files to EPIC v4 
          to = paste0(newDir, Lepr), overwrite = TRUE)
}

```


## OPC

<!-- Operation schedules  -->

### OPSCCOM

*OPSCCOM.dat*

?

```{r PARALLEL OPSCCOM}

for(i in 1:8) {
  opsccom <- phu_cal_PAR %>% 
    filter(parallel == i) %>% 
    select(runid) %>% 
    mutate(file = paste(runid,".opc", sep = "")) %>%
    distinct()
  dir.create (paste0(path_out, crop, "/OPSC_parallel/OPSC_", i), showWarnings = FALSE)
  path_temp <- paste0(path_out, crop, "/OPSC_parallel/OPSC_", i)
  write.fwf(opsccom, paste0(path_temp, "/OPSCCOM.dat"),
          rownames = FALSE, colnames = FALSE,
          formatInfo = TRUE, sep = "  ")
  write.fwf(opsccom, paste0(path_epic, "EPIC_CS_", i, "/OPSC/OPSCCOM.dat"),
          rownames = FALSE, colnames = FALSE,
          formatInfo = TRUE, sep = "  ")
  }

# FILE EXISTS: `r file.exists(paste0(path_epic, "EPIC_CS_", i, "/OPSC/OPSCCOM.dat)`
# LAST MODIFIED:  `r file.info(paste0(path_epic, "EPIC_CS_", i, "/OPSC/OPSCCOM.dat)$ctime`
```


### OPS FILES IN R

```{r PARALLEL OPS FILES PRINT IN R}

if(crop == "ALFA"){
  cropp <- "ALF"
} else if (crop == "BARL"){
  cropp <- "BAR"
} else if (crop == "CSIL"){
  cropp <- "MAI"
} else if (crop == "CORN"){
  cropp <- "MAI" # ???????????????????????????????????????
} else if (crop == "OATS"){
  cropp <- "OAT"
} else if (crop == "FPEA"){
  cropp <- "PEA"
} else if (crop == "POTA"){
  cropp <- "POT"
} else if (crop == "RAPE"){
  cropp <- "RAP"
} else if (crop == "RYE") {
  cropp <- "RYE"
} else if (crop == "SGBT"){
  cropp <- "SGB"
} else if (crop == "SUNF"){
  cropp <- "SNF"
} else if (crop == "SOYB"){
  cropp <- "SOY"
} else if (crop == "WWHT"){
  cropp <- "WHE"
} else {
  print("ZEROO")
}


# *** READ *** READ *** READ ** READ ***
# phu_cal <- read.table(paste0(path_out, crop, "/", crop, "_phu_cal.csv"), header = TRUE, sep = ";")
phu_cal_PAR <- read.table(paste0(path_out, crop, "/", crop, "_phu_cal_PAR.csv"), 
                          header = TRUE, sep = ";")
crop_cal <- read.table(paste0(path_out, crop, "/", crop, "_cultivars.csv"), header = TRUE, sep = ",")
crop_parm <- read.table(paste0(path_tab, "OPSC_Param_SVK13.txt"), header = TRUE, sep = ";")  # all crops by default
# *** READ *** READ *** READ ** READ ***

crop_parm <- crop_parm %>%
  filter(CROP == cropp)  %>%   # filter parameters for current crop only
  select(-CROP)

if(unique(crop_cal$CROPID == 155)){
  crop_cal$CROPID <- 2
} else {print("zeroo")} # CORN cropid == 2, COR3 cropid == 155

if(unique(phu_cal_PAR$cropid == 155)){
  phu_cal_PAR$cropid <- 2
} else {print("zeroo")} # CORN cropid == 2, COR3 cropid == 155

# combine tables for OPSC / step by step according to ms access

opsc1 <- phu_cal_PAR %>% 
  select(-cropid, -crop, -LVP) %>% 
  merge(crop_cal, by = c("PLN_JUL", "HRV_JUL")) 
opsc2 <- merge(opsc1, crop_parm, by = "CROPID") # 24057 (grid*cultivars) * 6 (operations) = 144342  

opsc3 <- opsc2 %>% # 8640
  mutate(OPMONTH = case_when(OPERATION %in% c("HARV", "KILL") ~ HRV_MON,
                             OPERATION %in% c("FRTK", "FRTP", "TILL", "SOW") ~ PLN_MON)) %>%
  mutate(OPDAY = case_when(OPERATION %in% c("HARV", "KILL") ~ HRV_DAY,
                           OPERATION %in% c("FRTK", "FRTP", "TILL", "SOW") ~ PLN_DAY)) %>%
  mutate(Seq = case_when(seas == "SPG" ~ Seq1, 
                         seas == "WIN" ~ Seq2))  %>% # sequence of operations differ for SPG and WIN crops
  mutate(PARAMETER2 = case_when(OPERATION == "SOW" ~ round(PHU, 0),
                                OPERATION %in% c("FRTK", "FRTP") ~ 25, TRUE ~ 0)) %>%  # https://www.sharpsightlabs.com/blog/case-when-r/
  mutate(PARAMETER0 = 0.00) %>% 
  mutate(PARAMETER100 = 0.00) %>% 
  select(parallel, ctry, runid, scenario, GRID,	CROPID,	CROP,	CropSpec,	
         OPERATION,LUN, Year, OPMONTH, OPDAY, Seq,	IHC,	TYPE,	PARAMETER1,	PARAMETER2,	PARAMETER3,
         PARAMETER4, PARAMETER5,	PARAMETER6,	PARAMETER7,	PARAMETER0, PARAMETER100) %>% 
  arrange(GRID, scenario, Seq)


# print files to cult folder

# head of OPS file + ops file export !!! TAKES AGES !!!

for(i in 1:8) {
  parall <- opsc3 %>% # parall == df with data only for specific par folder
    filter(parallel == i)
  dir.create(paste0(path_out, crop, "/OPSC_parallel/OPSC_", i), showWarnings = F) # create 8 OPCS folders
  path_temp <- paste0(path_out, crop, "/OPSC_parallel/OPSC_", i) # set path to the folder
  for(j in parall$runid){ # for each run id in actual parallel
    file.create(paste0(path_temp, "/", j, ".opc")) # create file
    opc_file <- paste0(path_temp, "/", j, ".opc") # sign the file to the variable opc_file
    txt <- (paste("Operations for runid", j, "crop =", crop, ", EPIC-IIASA CZ, version 4"))
    write.table(txt, file = paste(opc_file), 
              append=F, quote = F, col.names = F, row.names = F)  
    txt2 <- ("   3   0")
    write.table(txt2, file = paste(opc_file), 
              append=T, quote = F, col.names = F, row.names = F) 
    opsfile <- parall %>% 
        filter(runid == j) %>% 
        select(Year, OPMONTH, OPDAY, TYPE, CROPID, PARAMETER1, PARAMETER2, PARAMETER3, # TYPE == operation id
               PARAMETER4, PARAMETER0, PARAMETER5, PARAMETER6, PARAMETER7, PARAMETER100)
    write.fwf(opsfile, file = paste(opc_file),
          rownames = F, colnames = F, append=T,
          width = c(2,2,2,5,10,5,8,8,8,8,8,8,8,8), sep = "") # write j to the opc_file APPEND = T

  }
}

# copy files to v4

for(i in 1:8) {
  path_temp <- paste0(path_out, crop, "/OPSC_parallel/OPSC_", i, "/") # set path to the folder
  Lopc <- list.files(path_temp, pattern = "opc") # get list of opc files in folder
  newDir <- (paste0(path_epic, "EPIC_CS_", i, "/OPSC/")) # set new folder (EPIC v4)
  file.copy(from = paste0(path_temp, Lopc),   # copy opc files to EPIC v4 
          to = paste0(newDir, Lopc), overwrite = TRUE)
}

```


## SITE

### SITECOM

*SITECOM.dat*

(same as SITE0810.dat)

Catalog of site files available for the project

EPIC looks in the site catalog file SITE0810.dat (or the catalog named in EPICFILE.dat) for the site number referenced in EPICRUN.dat and obtains the name of the file containing the site-specific data.
The site-specific file is used to describe each Hydrologic Landuse Unit (HLU), which is
homogenous with respect to climate, soil, landuse, and topography. The site may be of
any size consistent with required HLU resolution. Site files (filename.sit ) describe each
site: latitude, longitude, elevation, area, etc. A project may involve several sites
(typically fields, but could be a larger area). Sites (fields) may contain buffers and filter
strips, etc.
The site catalog SITE0810.dat and the site files can be renamed and edited.


```{r PARALLEL SITECOM}

# *** READ *** READ *** READ ** READ ***
# phu_cal <- read.table(paste0(path_out, crop, "/", crop, "_phu_cal.csv"), header = TRUE, sep = ";")
# *** READ *** READ *** READ ** READ ***

for(i in 1:8) {
  sitecom <- phu_cal_PAR %>%
    filter(parallel == i) %>%
    mutate(ref = case_when(ctry == "CZ" ~ "119",
                            TRUE ~ "6135")) %>%
    mutate(file = case_when(ctry == "CZ" ~ "119.sit",
                            TRUE ~ "6135.sit")) %>%
    select(ref, file) %>%
    distinct()
  dir.create(paste0(path_out, crop, "/SITE_parallel/SITE_", i), showWarnings = FALSE)
  path_temp <- paste0(path_out, crop, "/SITE_parallel/SITE_", i)
  write.fwf(sitecom, paste0(path_temp, "/SITECOM.dat"),
          rownames = FALSE, colnames = FALSE,
          formatInfo = TRUE, sep = "  ")
  write.fwf(sitecom, paste0(path_epic, "EPIC_CS_", i, "/SITE/SITECOM.dat"),
          rownames = FALSE, colnames = FALSE,
          formatInfo = TRUE, sep = "  ")
  }


# BACKUP FOR MORE COMPLICATED SITECOMS

# for(i in 1:8)) {
#   sitecom <- phu_cal_PAR %>% 
#     filter(parF == i) %>% 
#     mutate(file = case_when(cntry == "CZ" ~ "119.sit",
#                             TRUE ~ "6135.sit")) %>%
#     select(runid, file) %>% 
#     distinct()
#   dir.create(paste0(path_out, crop, "/SITE_parallel/SITE_", i), showWarnings = FALSE)
#   path_temp <- paste0(path_out, crop, "/SITE_parallel/SITE_", i)
#   write.fwf(sitecom, paste0(path_temp, "/SITECOM.dat"),
#           rownames = FALSE, colnames = FALSE,
#           formatInfo = TRUE, sep = "  ")
#   write.fwf(sitecom, paste0(path_epic, "EPIC_CS_", i, "/SITE/SITECOM.dat"),
#           rownames = FALSE, colnames = FALSE,
#           formatInfo = TRUE, sep = "  ")
#   }

# WORKS !! 16/08/2022

```

## SOIL

### SOILCOM

*SOILCOM.dat*

(same as SOIL0810.dat) 

Catalog of soil data files

Soils EPIC looks in the soil catalog file SOIL0810.dat (or the catalog named in EPICFILE.dat) for the soil number referenced in EPICRUN.dat and obtains the name of the file containing the soil-specific data.
The soil-specific file named filename.sol listed in the catalog file contains data
describing the soil profile and the individual horizons. The study may involve several
different soils for the farm or watershed analysis and are selected for use in the subarea
file.
The soil catalog SOIL0810.dat and the soil files can be renamed and edited.


```{r PARALLEL SOILCOM}

# *** READ *** READ *** READ ** READ ***
# phu_cal <- read.table(paste0(path_out, crop, "/", crop, "_phu_cal.csv"), header = TRUE, sep = ";")
# *** READ *** READ *** READ ** READ ***

for(i in 1:8) {
  soilcom <- phu_cal_PAR %>% 
    filter(parallel == i) %>% 
    mutate(ref = case_when(ctry == "CZ" ~ "10",
                            TRUE ~ "7")) %>%
    mutate(file = case_when(ctry == "CZ" ~ "10.sol",
                            TRUE ~ "7.sol")) %>%
    select(ref, file) %>% 
    distinct()
  dir.create(paste0(path_out, crop, "/SOIL_parallel/SOIL_", i), showWarnings = FALSE)
  path_temp <- paste0(path_out, crop, "/SOIL_parallel/SOIL_", i)
  write.fwf(soilcom, paste0(path_temp, "/SOILCOM.dat"),
          rownames = FALSE, colnames = FALSE,
          formatInfo = TRUE, sep = "  ")
  write.fwf(soilcom, paste0(path_epic, "EPIC_CS_", i, "/SOIL/SOILCOM.dat"),
          rownames = FALSE, colnames = FALSE,
          formatInfo = TRUE, sep = "  ")
  }


# BACKUP FOR MORE COMPLICATED SOILCOMS

# for(i in 1:8) {
#   soilcom <- phu_cal_PAR %>% 
#     filter(parF == i) %>% 
#     mutate(file = case_when(cntry == "CZ" ~ "10.sol",
#                             TRUE ~ "7.sol")) %>%
#     select(runid, file) %>% 
#     distinct()
#   dir.create(paste0(path_out, crop, "/SOIL_parallel/SOIL_", i), showWarnings = FALSE)
#   path_temp <- paste0(path_out, crop, "/SOIL_parallel/SOIL_", i)
#   write.fwf(soilcom, paste0(path_temp, "/SOILCOM.dat"),
#           rownames = FALSE, colnames = FALSE,
#           formatInfo = TRUE, sep = "  ")
#   write.fwf(soilcom, paste0(path_epic, "EPIC_CS_", i, "/SOIL/SOILCOM.dat"),
#           rownames = FALSE, colnames = FALSE,
#           formatInfo = TRUE, sep = "  ")
#   }

# WORKS !! 16/08/2022
```

## BATCH FILE

```{r BATCHFILE PRINT}

for(i in 1:8) {
  path_temp <- paste0("c:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/EPIC_CS_", i, "/EPIC0810/")
  path_batch <- paste0("C:/Users/krizovak/Documents/__EPIC__/EPIC_CS_v4_Aug2022/EPIC_CS_", i)
  Leprun <- list.files(path_temp, pattern = "epicrun_")
  file.create(paste0(path_batch, "/RunEPIC_batch_", i, ".bat"))
  batchfile <- paste0(path_batch, "/RunEPIC_batch_", i, ".bat")
  line0 <- paste0("C:\\Users\\krizovak\\Documents\\__EPIC__\\EPIC_CS_v4_Aug2022\\EPIC_CS_", i, "\\EPIC0810")
  line2 <- paste0("cd ", line0)
  line4 <- ("")
  # txt <- paste("ECHO", line2, "PAUSE", line4, sep="\n")
  txt <- paste("ECHO", line2, line4, sep="\n") # wo PAUSE to be able to run all 8 batch files from 1 general batch file
  # write.table(txt, file = paste0(path_batch, "/RunEPIC_batch.bat"), 
  write.table(txt, file = paste(batchfile), 
              append=F, quote = F, col.names = F, row.names = F)  
  for(j in Leprun){
    line5 <- paste0("rename ", j, " epicrun.dat")
    line8 <- ("")
    txt2 <- paste(line5, "epic0810_fixed", "del epicrun.dat", line8, sep="\n")
    # write.table(txt2, file = paste0(path_batch, "/RunEPIC_batch.bat"), 
    write.table(txt2, file = paste(batchfile), 
              append=T, quote = F, col.names = F, row.names = F) 
  }
  txt3 <- "PAUSE"
  write.table(txt3, file = paste(batchfile), 
              append=T, quote = F, col.names = F, row.names = F) 
}


rm(path_batch)
rm(path_temp)
rm(Leprun)
rm(batchfile)
rm(line0)
rm(line2)
rm(line4)
rm(line5)
rm(line8)
rm(txt)
rm(txt2)
rm(txt3)

```


## PARMFILES

*`r crop`_PARM_cultivars_2print.txt*

?

necessary table: *CZ_PARM0810tab_v0.txt*




